{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ec5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#from imutils import face_utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "#import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e4fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пути до ресурсов\n",
    "DATASET_BINARY_DATA = r\"..\\binary_data/\"\n",
    "DATASET_ALL_DATA = r\"..\\all_data/\"\n",
    "OUTPUT_LANDMARKS_FOLDER = r\"..\\output_landmarks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e11c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем модель\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34220d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output_landmarks_file(image_name, label, landmarks):\n",
    "    image_name = os.path.splitext(image_name)[0]\n",
    "    # Папка для сохранения txt-файлов\n",
    "    output_dir = OUTPUT_LANDMARKS_FOLDER\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Путь к файлу, куда сохранить координаты\n",
    "    output_path = os.path.join(output_dir, f'{image_name}.txt')\n",
    "\n",
    "    # Сохраняем в файл\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(f'{label}\\n')\n",
    "        for x, y in landmarks:\n",
    "            f.write(f'{x} {y}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e4fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_landmarks(points):\n",
    "    points = points.astype(np.float32)\n",
    "    #points = landmarks.reshape(-1, 2)\n",
    "    left_eye = points[33]\n",
    "    right_eye = points[263]\n",
    "\n",
    "    center_x = (left_eye[0] + right_eye[0]) / 2\n",
    "    center_y = (left_eye[1] + right_eye[1]) / 2\n",
    "\n",
    "    points[:, 0] -= center_x\n",
    "    points[:, 1] -= center_y\n",
    "\n",
    "    eye_dist = np.linalg.norm(left_eye - right_eye)\n",
    "    if eye_dist > 0:\n",
    "        points = points / eye_dist\n",
    "    return points\n",
    "\n",
    "def get_landmarks(image_path, landmarks = []):\n",
    "    image_array = np.fromfile(image_path, dtype=np.uint8)\n",
    "    image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Изображение не загружено!\")\n",
    "            \n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    height, width = image_rgb.shape[:2]\n",
    "\n",
    "    # Детектируем лицо\n",
    "    faces = face_mesh.process(image_rgb)\n",
    "\n",
    "    if not faces.multi_face_landmarks:\n",
    "        return\n",
    "        #raise ValueError(\"Лицо не найдено на изображении\")\n",
    "\n",
    "    shape = faces.multi_face_landmarks[0]\n",
    "\n",
    "    landmarks = np.array([(p.x * width, p.y * height) for p in shape.landmark])\n",
    "    #landmarks = np.concatenate((np.concatenate((landmarks[pack_identify[\"first\"]], landmarks[pack_identify[\"second\"]]), axis=0), landmarks[pack_identify[\"third\"]]), axis=0).flatten()\n",
    "\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_key(name):\n",
    "    return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', name)]\n",
    "\n",
    "def build_dataframe(dataset_dir, all_landmarks, all_labels, get_label_func = lambda k : k // 8): # получаем числовой код папки\n",
    "    k = 0\n",
    "    for label_dir in sorted(os.listdir(dataset_dir), key=numeric_key):\n",
    "        label_path = os.path.join(dataset_dir, label_dir)\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "\n",
    "        for filename in os.listdir(label_path):\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_path = os.path.join(label_path, filename)\n",
    "\n",
    "                landmarks = get_landmarks(image_path)\n",
    "                if landmarks is None: continue\n",
    "                label = get_label_func(k) % 2\n",
    "                \n",
    "                all_landmarks.append(landmarks.flatten())\n",
    "                all_labels.append(label)\n",
    "\n",
    "                write_output_landmarks_file(filename, label, landmarks)\n",
    "\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_landmarks = []\n",
    "all_labels = []\n",
    "\n",
    "build_dataframe(DATASET_ALL_DATA, all_landmarks, all_labels) # получаем числовой код "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f33d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "for idx in list(range(0, 468)):\n",
    "    columns.append(f\"x{idx}\")\n",
    "    columns.append(f\"y{idx}\")\n",
    "\n",
    "df = pd.DataFrame(all_landmarks, columns=columns)\n",
    "df['label'] = all_labels\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(df[\"label\"].unique())\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3db5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\", sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5fca1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf4a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим данные\n",
    "#\n",
    "\n",
    "# X_train_binary, X_test_binary, y_train_binary, y_test_binary = train_test_split(\n",
    "#     df_binary.drop(columns=['label']),  # все колонки кроме 'label'\n",
    "#     df_binary['label'],                 # сами метки\n",
    "#     test_size=0.2,                # 20% на тест\n",
    "#     stratify=df_binary['label'],         # сбалансированная разбивка по классам\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# Обучим модель\n",
    "# model_subtype = LogisticRegression(max_iter=1000)\n",
    "# model_subtype.fit(X_train_subtype, y_train_subtype)\n",
    "\n",
    "# model_binary = LogisticRegression(max_iter=1000)\n",
    "# model_binary.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# # Оценим качество\n",
    "# # y_pred_subtype = model_subtype.predict(X_test_subtype)\n",
    "# # print(f\"Accuracy subtype: {accuracy_score(y_test_subtype, y_pred_subtype):.4f}\")\n",
    "\n",
    "# y_pred_binary = model_binary.predict(X_test_binary)\n",
    "# print(f\"Accuracy binary class: {accuracy_score(y_test_binary, y_pred_binary):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2027dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_dichotomy(image_path, model):\n",
    "#     landmarks = get_landmarks(image_path)\n",
    "    \n",
    "#     X_input = pd.DataFrame([landmarks], columns=columns)\n",
    "\n",
    "#     prediction = model.predict(X_input)[0]\n",
    "#     proba = model.predict_proba(X_input)[0]\n",
    "\n",
    "#     return prediction, proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d54c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(model_subtype, 'subtype_classifier.pkl')\n",
    "\n",
    "# joblib.dump(model_binary, 'logic_ethics_classifier.pkl')\n",
    "\n",
    "# subtypes = {\n",
    "#     0 : \"Шизоидный\",\n",
    "#     1 : \"Параноидальный\",\n",
    "#     2 : \"Нарциссический\",\n",
    "#     3 : \"Психопатический\",\n",
    "#     4 : \"Компульсивный\",\n",
    "#     5 : \"Истерический\",\n",
    "#     6 : \"Депрессивный\",\n",
    "#     7 : \"Мазохистический\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94b567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_subtype_file = joblib.load(\"subtype_classifier.pkl\")  # путь к сохранённой модели\n",
    "# model_binary_file = joblib.load(\"logic_ethics_classifier.pkl\")  # путь к сохранённой модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89de35c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Инициализация детектора и предиктора\n",
    "# result_subtype, confidence_subtype = predict_dichotomy(\"../all_data/12/16 (2).jpg\", model_subtype_file)\n",
    "# print(f\"Подтип личности: {subtypes[result_subtype]} (Уверенность: {max(confidence_subtype):.2f})\")\n",
    "\n",
    "# result_binary, confidence_binary = predict_dichotomy(\"../all_data/12/16 (2).jpg\", model_binary_file)\n",
    "# print(f\"Дихотомия: {'Этика' if result_binary == 0 else 'Логика'} (Уверенность: {max(confidence_binary):.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8abfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_landmarks(landmarks):\n",
    "#     \"\"\"\n",
    "#     landmarks: np.array с shape (N, 2), координаты в пикселях\n",
    "#     Возвращает: нормализованные landmarks и параметры центра и масштаба\n",
    "#     \"\"\"\n",
    "#     left_eye = landmarks[33]\n",
    "#     right_eye = landmarks[263]\n",
    "#     center = (left_eye + right_eye) / 2\n",
    "#     scale = np.linalg.norm(left_eye - right_eye)\n",
    "\n",
    "#     normalized = (landmarks - center) / scale\n",
    "#     return normalized, center, scale\n",
    "\n",
    "\n",
    "# def denormalize_landmarks(normalized, center, scale):\n",
    "#     \"\"\"\n",
    "#     Восстанавливает нормализованные точки обратно в пиксельные координаты\n",
    "#     \"\"\"\n",
    "#     return (normalized * scale) + center\n",
    "\n",
    "# def draw_normalized_landmarks(image_path):\n",
    "#     # 1. Загрузка изображения\n",
    "#     image = cv2.imread(image_path)\n",
    "#     if image is None:\n",
    "#         raise ValueError(\"Не удалось загрузить изображение\")\n",
    "#     h, w = image.shape[:2]\n",
    "\n",
    "#     # 2. Инициализация MediaPipe\n",
    "#     mp_face_mesh = mp.solutions.face_mesh\n",
    "#     face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)\n",
    "\n",
    "#     # 3. Обработка изображения\n",
    "#     rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     results = face_mesh.process(rgb)\n",
    "\n",
    "    # 4. Проверка наличия лица\n",
    "    # if not results.multi_face_landmarks:\n",
    "    #     print(\"Лицо не найдено\")\n",
    "    #     return\n",
    "\n",
    "    # # 5. Извлечение точек и нормализация\n",
    "    # face_landmarks = results.multi_face_landmarks[0]\n",
    "    # landmarks = np.array([\n",
    "    #     [lm.x * w, lm.y * h]\n",
    "    #     for lm in face_landmarks.landmark\n",
    "    # ])\n",
    "    # normalized, center, scale = normalize_landmarks(landmarks)\n",
    "    # restored = denormalize_landmarks(normalized, center, scale)\n",
    "\n",
    "    # # 6. Отображение денормализованных точек\n",
    "    # for point in restored.astype(int):\n",
    "    #     x, y = point\n",
    "    #     cv2.circle(image, (x, y), radius=1, color=(0, 255, 255), thickness=-1)\n",
    "\n",
    "    # # 7. Отображение изображения\n",
    "    # cv2.imshow(\"Normalized landmarks (restored)\", image)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f844fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw_normalized_landmarks(\"../all_data/12/16 (2).jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
